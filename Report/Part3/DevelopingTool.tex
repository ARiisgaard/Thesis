\chapter{Developing the tool}\label{CDevelopingTool}

In this chapter it is explained how the tool has been developed. The two sections is describing the coding languages used and the plugins used to create the tool. The following sections are describing the necessary steps to build the tool. These steps can be seen in figure \ref{DevelopmentSteps}.


\begin{figure} [H]
	\centering
	\includegraphics[width=1\textwidth]{Pictures/DevelopmentSteps}
	\caption{An overview of the code}
	\label{DevelopmentSteps}
\end{figure}

First it is necessary to divide the raster into tiles to be able to limit the loaded data to the current extent. How this is done is explained in section x. Section x describes how the tiles have been visualized. To be able to color the tiles based on the current values one must know what the current values are. In section x it is explained how this information is calculated. The raster layer is then rerendered with these values as described in section x. Lastly some measurements were taken to ensure a more user-friendly experience. These additions are described in section x. 


%\chapter{Coding languages and plugins} \label{CCodingLanguages}

%In this chapter the coding languages and plugins used to develop the tool is explained. Before this explanation a quick overview of how the tool has been developed


For this project, the coding language Python was used to create the tiles, while visualization of the tiles was done in a webgis build with the languages HTML, CSS and Javascript. This webgis map has been tested on a local caddy server for reasons explained in section x

\section{Languages}
\subsection*{Python}
Python is a programming language with a simple syntax, which functions across multiple different platforms. This simple syntax means that Python can achieve the same as some other coding languages in fewer lines.\citep{WhatIsPython}
Python was used in this project because of the gdal library expanded further upon in section x
This project has been using version 3.8.3 of Python, which at the time of writing is the latest version. \citep{PythonVersion}
\subsection*{HTML}
HTML is short for Hyper Text Markup Language. It is the language used for defining and structuring a web page’s content.
\subsection*{CSS}
CSS is an abbreviation for Cascading Style Sheets. This language defines how the HTML will be displayed.
\subsection*{Javascript}
How a webpage behaves is defined by the language Javascript.  This is what makes the web page interactive. 
\citep{WhatIsJs}

\section{Libraries}
To transform the raster data into smaller tiles the python library Gdal is used. 
\subsection*{Gdal}
GDAL is library for translating between multiple different geospatial data formats. \citep{GDAL} 

Included in this library is the gdal2tiles program, which can divide raster files into smaller tiles. 
At the time of using this program it was only able to generate tiles structured after the TMS standard. The function to follow the XYZ structure was added the 3th of May 2020 \citep{gdal2tilesDoc} \citep{GdalRelease}
%
The script rendering the tiles in the map was based on the XYZ structure. This meant that the rows of tiles were ordered incorrectly when the generated tiles were imported. Therefore, the official version of gdal2tiles was replaced by a version made by a github user named commenthol. This version is modified to allow the creation of tiles following the XYZ structure. \citep{gdalLeaflet}
Both the official version and the modified version have their output format as mbtiles with a bit depth of 8 bit. To be usable for this project a bit depth of at least 32 bit is needed, as mentioned in section x. The workaround for this issue will be explained in section x. 
\subsection*{Openlayers}
The map in which the tiles are being showed are created in Openlayers, which is an open source JavaScript library for creating dynamic maps for web pages. 
\citep{OL}
Openlayers was chosen because the tool presented in related work was built in Openlayers. Therefore, using Openlayers enables expanding upon this existing tool instead of starting from scratch. 

The existing tool was created with the debug version of Openlayers, which this tool also have build on. The debug version is a version of the Openlayers, which have not been minified. Because of this it is a larger file than the regular one. 
https://gis.stackexchange.com/questions/155529/whats-difference-between-ol-js-and-ol-debug-js-files-in-openlayers-3

Attempts at replacing it with the minified version resulted in errors from olGeoTiff, which have been build based on the debug version. Optimizing other parts of the code was given higher priority, so the debug version never got replaced. 

\subsection*{olGeoTiff}
olGeoTiff is a Javascript class for visualising geotiff tiles in Openlayers, utilising the libraries geotiff.js and Plotty. The visualized tiles are being processing in the client instead of on a server. It was used in the map presented in section x. 
The class is a modified version of Openlayers WMTS layer, where the internal tile loading function has been changed. The regular function would request precolored tiles and then add them to the map. The tiles requested by the modified version are not precolored and need to be processed before getting added to the map. A simplified illustration of this processing is illustrated in figure x. This simplified figure is enough to explain the mechanics of the class but does not detail the callback function structure. Aside from being used for error handling callbacks are also necessary to ensure that Openlayers do not try to add the tiles to the map, before they have been processed. More detailed figures can be found in \citep{Baumrocks} thesis.

\begin{figure} [H]
	\centering
	\includegraphics[width=.8\textwidth]{Pictures/olGeoTiffSimplified}
	\caption{A simplified illustration of how olGEoTiff functions}
	\label{olGeoTiffSimplified}
\end{figure}

To ensure that tiles are only being downloaded once an object keeps track of all the downloaded data. The object is organized by the tiles’ url. 
Whenever tiles are being requested the object will always be checked to see if it already contains the url. If it does not the object will be updated to include the requested tile. The tile will then be loaded before being processed. \citep{Baumrocks}
The processing is done with the TIFF parser geotiff.js 
\citep{Geotiff}
and Plotty, which is a library for creating images from data arrays \citep{Plotty}.

The loaded tiles first get parsed with geotiff.js and added to the object before Plotty get used to render tiles in the designated colors. Then the tiles get added to the map.
\citep{Baumrocks}
The olGeoTiff also have a redraw function, which when triggered will redraw the tile layer based on the current designated colors. This was for instance used in Bernnard Baumrocks map, whenever the color sliders were changed. 

\section{Testing server}
%Not finished 
To test the tool a local test server was set up. This was initially a Python-based http server, but was later replaced with a Go-based Caddy server to improve performance. The performance difference between the two is elaborated upon in section x.

Caddy was chosen because it supports the second version of Hyper Text Transfer Protocol (HTTP)
\citep{WhyCaddy}



which is used for the communication between the client and server.
\citep{WhatIsHTTP}

HTTP/2 is allowing a faster communication between them

\citep{HTTP2}
%Caddy
%http’s limits to 6 connections 
%fig text: Blue: DomContentLoaded Red: Load

\section{Creating the tiles}
The tiles were created using a modified version of gdal2tiles, which was changed to create tiles following the XYZ format. However, since the default output bit depth is too low, it would have to be modified further. The file format would also have to be changed to tiff in order to be visualized with the geotiff.js library. 

\subsection{Changing the file type}
Changing the file format can be done by changing two lines in the gdal2tiles script:

\begin{lstlisting}[language=iPython, caption={Changing the file format}, label= VoresPY,escapechar=|]
#Original code
#self.tiledriver = 'PNG'
#self.tileext = 'png'
#New code
self.tiledriver = 'GTiff'
self.tileext = 'tiff'
\end{lstlisting}
This changes the raster driver from png to the geotiff format and the file extension from png to tiff. 
\citep{RasterDrivers}
The geospatial information, which is the difference between a geotiff and a regular tiff, gets lost in process. This information is not important for this project since the tiles are being loaded based on their name and folder placement, not based on the internal metadata.

Running gdal2tiles with these changes will produce a tiff file, which still would be limited to 8 bits. 
\subsection{Increasing the bit depth}
The reason for the bit limit is that gdal2tiles uses the memory dataset driver, which have 8 bits as default.  This default can overwritten to 32 bits by adding “gdal.GDT\_Int32” to every instance where the driver is being used as demonstrated in code x. 
\citep{MoreThan8}

\begin{lstlisting}[language=iPython, caption={Increasing the bit depth}, label= VoresPY,escapechar=|]
self.mem_drv = gdal.GetDriverByName('MEM')
...
#Old code
#dstile = mem_drv.Create('', tile_size, tile_size, tilebands)
#New code
dstile = self.mem_drv.Create('', self.tilesize, self.tilesize, tilebands, gdal.GDT_Int32)
\end{lstlisting}
The memory driver is being used four times, which all have been changed in a similar fashion.


The script is now generating tiff tiles correctly. However it also generates KML files for visualization in Google Earth, which is undesired since it would increase the processing time and required storage space. 
\subsection{Prevent generation of Google Earth files}
gdal2tiles is automatically generating KML files if the projection is EPSG:4326. According to the documentation for the official gdal2tiles this can be disabled with the command "--no.kml".
\citep{gdal2tilesDoc}


This command does not prevent the creation of the files in the modified version. Therefore the automatic generation has been removed from the code. This was done by commenting out the lines shown in x. 

\begin{lstlisting}[language=iPython, caption={Increasing the bit depth}, label= KML,escapechar=|]
 if self.out_srs and srs4326.ExportToProj4() \
         == self.out_srs.ExportToProj4():
     self.kml = True
     self.isepsg4326 = True
     if self.options.verbose:
         print('KML autotest OK!')
\end{lstlisting}
        
\subsection{Command for tile creation}

After all the modification are in place the script can be run by running the command illustrated below:


python <path to modified gdal2tiles script> --leaflet --zoom=<desired zoom levels> --profile=raster --webviewer=none <input file> <output directory>


Most of these inputs are from the documentation for the original gdal2tiles, though the leaflet command is from the modified version. This command ensures that tiles are being created following the XYZ formatting instead of the TMS. The zoom command defines which zoom levels should be generated. An example of an input could be 0-2, which would generate tiles for the zoom levels 0, 1 and 2. 

Setting the profile to raster was done because the two other options (mercator and geodetic) resulted in the error message "list index out of range", while the raster profile gave a useable product. The selection of this options and its consequences is expanded upon in section x.  

The webviewer option prevent the generation of webviewers to visualize the tiles. These default webviewers is created to visualize tiles of the original format, so they would be unable to visualize the modified tiles. 
The input file is the name of the processed file and output directory is the folder, where the tiles get created. 
\subsection{Result}

While creating the tiles the error message "ERROR 1: Buffer too small" gets displayed. The tiles are still being generated with the correct formatting and bit depth. This is an error message from numpy, which gdal2tiles are using. 
\citep{MoreThan8}
The generated tiles appears as they should, so this error message is potentially referring to the geospatial information, which gets lost.

%The tiles at the rightmost and bottom edges have an edge as shown in figure x. This edge is not being shown, when the tile is being loaded into the map. A comparison between the input file and the tile shows that all data is being displayed. The bottom part of the input file is the last part before the edge. This edge seems to be generated because the input file was not perfectly dividable with the tile size as illustrated in figure x.
%https://github.com/ARiisgaard/Thesis/issues/22
%This edge could be another explanation for the error message. 

The script also produces an xml file with metadata. An example of the content of said metadata file can be seen in code \ref{metaData}.

\begin{lstlisting}[language=HTML5, caption={The metadata from the xml file generated by the modified gdal2tiles}, label= metaData,escapechar=|]
<?xml version="1.0" encoding="UTF-8"?>
<TileMap tilemapservice="http://tms.osgeo.org/1.0.0" version="1.0.0"><Abstract/><SRS>GEOGCS["WGS 84",DATUM["WGS_1984",SPHEROID["WGS 84",6378137,298.257223563,AUTHORITY["EPSG","7030"]],
AUTHORITY["EPSG","6326"]],PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],UNIT["degree",0.0174532925199433,
AUTHORITY["EPSG","9122"]],AXIS["Latitude",NORTH],AXIS["Longitude",EAST],AUTHORITY["EPSG","4326"]]
</SRS><BoundingBox maxy="25.00000000000814" maxx="80.99999999999989" miny="19.00000000000815" minx="72.99999999999989"/><Origin y="19.00000000000815" x="72.99999999999989"/><TileFormat extension="tiff" mime-type="image/tiff" height="256" width="256"/><TileSets profile="raster"><TileSet order="2" units-per-pixel="0.00833333333333" href="2"/><TileSet order="3" units-per-pixel="0.00416666666667" href="3"/><TileSet order="4" units-per-pixel="0.00208333333333" href="4"/><TileSet order="5" units-per-pixel="0.00104166666667" href="5"/><TileSet order="6" units-per-pixel="0.00052083333333" href="6"/><TileSet order="7" units-per-pixel="0.00026041666667" href="7"/><TileSet order="8" units-per-pixel="0.00013020833333" href="8"/><TileSet order="9" units-per-pixel="0.00006510416667" href="9"/></TileSets></TileMap>
\end{lstlisting}

\section{Processing time}\label{TilesTime}

\begin{figure} [H]
	\centering
	\includegraphics[width=.6\textwidth]{Pictures/ProcessingTime}
	\caption{Illustration of the area used for timing the tile generation}
	\label{ProcessingTime}
\end{figure}

The processing time is tested using the area of India shown in figure \citep{ProcessingTime}. This polygon with a 9 291 842 km$^2$ area was processed into tiles for each zoom level between 0 to 9. This is the equivalent of 349525 tiles as calculated with the formula presented in section x. 
\begin{equation}
2^{2n}
2^{2*9}+2^{2*8} .. . 2^{2*0} = 349525 tiles
\end{equation}
The creation of these tiles took 6 hours and 4 minutes and requires 6,52 GB of diskspace The amount of time mainly depends on the highest zoom level, since the number of tiles in a layer get quadrupled whenever the zoom level increases. In comparison the same area at the zoom levels 0-7 only took 22 minutes.

This processing time is not ideal, but it can theoretically be shortened with multiprocessing.
\subsection{Parallel processing of tiles}
Multiprocessing is the usage of multiple of the computer’s processors. Python is by default only able to use a single processor, even if multiple are available.  This can be circumvented with the multiprocessing module.
%Must not be reliant on previous outcomes
%Does not need to be executed in a particular order
%Does not return anything that would need to be accessed later in the code
\citep{Multiprocessing}
The modified version by \citet{gdalLeaflet} also has a multiprocessing version allowing each processer of the computer to work separately on generating tiles. However, the task is not properly distributed between the processes. This means that not all of the tiles are being generated. 
\citep{NoMulti}
Therefore, the slower single process version has been used for this project.


\section{Visualizing tiles}
After the tiles are created, they are stored in a folder, which is uploaded to the testserver along the index file. 
The metadata from the xml file must be loaded into the map to be able to visualize the tiles. Normally this could be done using the WMTSCapabilities() function in Openlayers.
\citep{WmtsOl}
However, the formatting of the xml file produced by gdal is different from the format, which this function can read. Therefore, a small script has been created to parse the xml file and store the information in a metadata object. This object, tileMetadata, stores the bounding box, origin, center coordinates as well as tilesize. The initial version of the object also stored the resolution data, which is called units-per-pixel in code x. This led to some inconsistency when loading tiles, that had been generated without some of the lower zoom level. This will be further expanded upon in section x. Therefore, the resolution was instead generated using the script x, where 0.0333 is the value for units-per-pixel at zoom level 0. 

\begin{lstlisting}[language=JavaScript, caption={The JavaScript in the project}, label= VoresJS,escapechar=|]
for (var z = 0; z < 14; ++z) {
// generate resolutions and matrixIds arrays for this WMTS
//The number in the resolution calculation is the units-per-pixel value at zoomlayer 0 in the xml file generated by gdal2tiles
resolutions[z] = 0.03333333333514 / Math.pow(2, z);
matrixIds[z] = z;
}
\end{lstlisting}
Using this metadata, the tiles could be visualized using the olGeoTiff class. 

%\begin{lstlisting}[language=JavaScript, caption={The JavaScript in the project}, label= VoresJS,escapechar=|]
%var wmslayer = new ol.layer.Tile({
%  source: new ol.source.WMTS({
%    url: tileFolders + '/{TileMatrix}/{TileCol}/{TileRow}.tiff',
%    projection: projection,
%    tileGrid: new ol.tilegrid.WMTS({
%      origin: tileMetadata[origin],
%      resolutions: resolutions,
%      matrixIds: matrixIds,
%      tileSize: tileMetadata[tileSize],
%    }),
%    requestEncoding: 'REST',
%    transition: 0
%  }),
%  extent: tileMetadata[boundingBox],
%  opacity: 0.65 
%});
%var olgt_map = new olGeoTiff(wmslayer);
%\end{lstlisting}


\subsection{Custom colors scheme}
Using colorbrewer a custom sequential colorscheme was generated. This scheme was added to Plotty and selected as a color palette. 

\begin{figure} [H]
	\centering
	\includegraphics[width=.4\textwidth]{Pictures/CScale}
	\caption{The color scale added to the map. When mousing over a color, the assigned value is displayed}
	\label{CScale}
\end{figure}

The value assigned to each color can be found by mousing over the color as shown in figure \ref{CScale}


\section{Loading data at a wrong resolution}\label{PresentingBug}

Figure \ref{MapWithWrongResolution} shows how the map looked, when the tiles are visualized. 
\fxnote{Rewrite this with new knowledge}

\begin{figure} [H]
	\centering
	\includegraphics[width=.6\textwidth]{Pictures/MapWithWrongResolution}
	\caption{The map is looking correct, but with tiles from the wrong zoom level}
	\label{MapWithWrongResolution}
\end{figure}


While the map appeared to look alright, it was loading tiles from the wrong zoom level. The tiles always got loaded from a zoom level three levels higher than intended. So the map in figure \ref{MapWithWrongResolution} is visualizing the map at zoom level 7, but loading and displaying tiles from zoom level 2. It was not possible to force the map to load tiles from a different zoom level.

Some experiments with loading tiles from the current view and zoom level 7 crashed the map with the error message “Insufficient Resources”. The amount of loaded tiles seems unnecessarily high and size of the tiles too small. This seems to indicate, that the tiles, which the modified version of gdal2tiles associates with zoom level 7 in fact belongs to a higher zoom level.

In figure \ref{DifferentZoom} these different zoom levels have been illustrated. The expected zoom level, which Openlayer

The Displayed zoom level (DZL) is the tiles, that are being loaded and visualised in Openlayers. The expected zoom level (EZL) is the zoom level, which Openlayers is displaying the map in. However as mentioned earlier there are too many tiles to load, when using this zoom level and map extent. The coloring should therefore ideally be done based on a zoom level between these two zoom levels. This zoom level have been defined as the intended zoom level (IZL).

\begin{figure} [H]
	\centering
	\includegraphics[width=.6\textwidth]{Pictures/DifferentZoom}
	\caption{An overview of the differences in zoom levels, which the map is displayed at (red), the displayed tiles get loaded in (green) and the zoom level, which should have been displayed (blue). The zoom level adjustment is the difference between the Expected and Intended zoom level}
	\label{DifferentZoom}
\end{figure}
\fxnote{Explain the need for zoom level 0 better}
This issue was not fixed, but theories behind the origin of it is discussed in section x. When the resolution data was gathered from the metadata file, the difference between the loaded and the actual zoom level would between different sets of tiles. This variance would depend on the which zoom levels were not being generated. So, if only the zoom levels 2-7 were generated, the difference would increase by one for each missing layer. In this case the loaded tiles would instead be wrong by 5, calculated as the default wrongness of 3 plus 2 for missing zoom layer 0 and 1. 
This bug will be defining for the rest of the code.



\section{Calculate max value in current extent}
Calculating the highest value in the current extent can be divided into two smaller tasks. Figuring out which tiles currently are being displayed and processing these tiles. 


\subsection{Current displayed tiles}\label{CurrentDisplayedTiles}

The tiles, which currently is within the view, can be found using the Openlayers tileGrid method forEachTileCoord. This method can trigger a function for each tile coordinate within a given zoom level and extent. 
\citep{forEachTileCoord}
These tile coordinates can then be translated to the tile name and folder location using getTileUrlFunction.
%The method is going through the tiles based on their coordinates, but this can be translated to the tile urls using the getTileUrlFunction.
\begin{lstlisting}[language=JavaScript, caption={}, label= VoresJS,escapechar=|]
var tileUrlFunction = wmslayer.getSource().getTileUrlFunction()
var zoomlevelAdjustment = 3
wmslayer.getSource().getTileGrid().forEachTileCoord(loadExtent, mapZoom - zoomlevelAdjustment, function(tileCoord) {
	tileName = tileUrlFunction(tileCoord, ol.proj.get('EPSG:4326'))
	maxValueInTile()
}
\end{lstlisting}
If the function is just given the zoom level of the map it will trigger for the tiles in the Expected Zoom Level. This would not work, since there are too many tiles in this level with the current extent. Instead the function is used with the Intended Zoom Level, which is calculated as the Expected Zoom Level minus a zoom level adjustment. Using an adjustment value of 3 was found to give a responsive user experience.

% This means that it on zoom level 7 would load the tiles, that should be rendered on zoom level 7. Due to the issue mentioned section \ref{PresentingBug} it is not the tiles from that zoom level, which are being displayed. Instead the tiles from zoom level 2 are being displayed. This will complicate some of the next steps. 
%The adjustment to the zoom level is in order to load the tiles, which should have been displayed.

\subsection{Max value for each tile}
If the tiles added to the map had been from the Intended Zoom Level, then the max value of a tile could have been calculated as olGeoTiff was running. olGeoTiff already holds the values for the tiles in a dataarray, so finding the maximum value could be done with a single line adding a tiles max value to the object for that tile. %This line is shown in code x, where urlToTiff is the name of the object, which holds the data.

%maxValueTileData[url].maxValue = Math.max(...urlToTiff[url][0])

However, since olGeoTiff holds data from an incorrect zoom layer this does not function. A possible solution would be to trigger forEachTileCoord for the Displayed Zoom Level. This solution was not implemented since the tiles from the Displayed Zoom Level are so large, that they would show data outside the view of the map. This means that the coloring could be based on the information that was outside of the current view.

The alternative solution is to run another function going through the tiles, which should have been displayed and find the highest value among these. This results in a map where the tiles from the Displayed zoom level were being colored based on information from the tiles at the Intended zoom level. This solution is by no means ideal. It means requesting tiles from two layers, one for displaying on the map a one for calculating the relevant max values. Loading more data than necessary will make the script slower, but since no better solution was found this have been implemented.

The calculation of the maximum value for each tile was done in a very similar fashion to how olGeoTiff operates as illustrated in figure \ref{CalculateMaxValue}. An object holds information about all tiles, which have been processed and the max value is known. When the function is run for a tile it first checks if the tile already has been processed. If that is not the case, then it will create an object for the data, which it then will load and parse with geotiff.js. %The data array with parsed data will then be run through as descripted in code x to calculate the maximum value. 
This maximum value will then be returned to the map. 

\begin{figure} [H]
	\centering
	\includegraphics[width=.6\textwidth]{Pictures/CalculateMaxValue}
	\caption{Flow diagram of the calculation over max value in a tile}
	\label{CalculateMaxValue}
\end{figure}



\subsection{Highest tile value currently displayed}


To find the largest tile value among all the currently displayed tiles forEachTileCoord is used. forEachTileCoord does not have a trigger for when it has run through all the tiles. This functionality is necessary for ensuring that the produced maximum value is actually the maximum value. Without a precise end trigger the coloring applied to the map could be based on the biggest value found before the coloring script stated running instead of the absolute highest value in the current display.
Since this trigger is necessary it has been created by running forEachTileCoord another time to count the number of tiles. This part of the code can be seen in code \ref{TilesInExtent}.
\begin{lstlisting}[language=JavaScript, caption={Counting the amount of tiles within the current extent}, label= TilesInExtent,escapechar=|] 
var tileNumber = 0;
wmslayerMap1.getSource().getTileGrid().forEachTileCoord(loadExtent, mapZoom - zoomlevelAdjustment, function(tileCoord) {
	tileNumber++;
})
\end{lstlisting}
The recoloring of the map can then be delayed until the function for calculating the maximum value have been running for the same amount of times as there are tiles on the map. In practical terms this can be accomplished by adding a counter and an if statement to the maximum-value-function. The counter would check how many times the function has run. The if statement would check if the amount of times the function had been run was equal to the number of tiles. If this is the case and the registered max value is different from the previous one the recolor function would trigger.
The calculation of the maximum value is the function presented in figure \ref{DoubleLoop}. It is running asynchronously because the array otherwise would be filled with “undefined” values instead of actual values. Running it asynchronously ensures that the script awaits the calculation of the value.  
\begin{figure} [H]
	\centering
	\includegraphics[width=1\textwidth]{Pictures/DoubleLoop}
	\caption{Finding the largest value in all currently displayed tiles}
	\label{DoubleLoop}
\end{figure}

\section{Recolor when the max value change}

The recoloring function was already part of olGeoTiff. However, in Bernhard Baumrocks’ thesis this recoloring was triggered manually by the user when changing the color sliders. In this project the changing of colors will trigger automatically. The function for recoloring the map have therefore been set up to trigger, when the user stops changing the view. By not triggering before the map movement is finished a smoother user experience is ensured, since new tiles does not have to processed before the user is finished with interacting with the map. The recolor function is running through all of the code mentioned in the previous sections. 

\begin{lstlisting}[language=JavaScript, caption={The JavaScript in the project}, label= VoresJS,escapechar=|]
map.on("moveend", function() {
recolorMap()
});
});
\end{lstlisting}
\section{Polish}
In addition to the rendering of the raster in the map, some features were also added to improve the user experience.

\subsection{Two maps}\label{DTTwoMaps}

\begin{figure} [H]
	\centering
	\includegraphics[width=.8\textwidth]{Pictures/Frontpage}
	\caption{A second map beside the first one. Each map is showing a different dataset as shown above the maps}
	\label{DualMaps}
\end{figure}

To be able to compare different rasters with each other a second map was added as illustrated in figure \ref{DualMaps}. This second map is having its own raster dataset but sharing the view with the first map. This means that the two maps would always show the same area. Panning or zooming in one map would do the same action in the other map. The two maps are sharing the same legend. Above each map is the name of the dataset, which is shown in the map.  

The two projection are also sharing the same color scale. This means that the coloring is done based on the maximum value in the current extent of either of the maps. To accomplish this changes were made to the function, which were finding the maximum value among the tiles as illustrated in figure \ref{ChangeToMaxCalculation}.
 
\begin{figure} [H]
	\centering
	\includegraphics[width=1\textwidth]{Pictures/ChangeToMaxCalculation}
	\caption{Calculating the maximum value for two maps. Changes from the original have been written in bold}
	\label{ChangeToMaxCalculation}
\end{figure}

This function is now being used twice, once for each layer. If the same function as presented in section x was used, then the redrawing would potentially trigger twice. 

To avoid this each of the maps are given their own processed tiles counter. The if statement, which is resetting the counters and triggering the recoloring, has been changed, so that it now is checking if both of these processed tiles counters is equal to the total number of tiles. Thereby the recoloring can only happen, when the tile in both maps have been processed. 

The two maps would always display the same amount of tiles, since they are sharing the same view. It is therefore only necessary to calculate the amount of tiles for one of the layers. 
%Add to dualmaps how the double evaluation for multiple maps were build 

The size of the maps were set to 400x400 pixels, which did not take up the full width of the page. This was done for both a performance and a scientific reason. From a performance perspective a small map requires less tiles and is therefore faster to loaded. Decreasing the width from using the full extent of the screen (700 pixels per map) improved the initial loading time from 5.31 seconds to 3.61 seconds. The measurement of performance is further elaborated in chapter \ref{EvalMethods}. 
The scientific reason is consistency in performance measurements. By having a fixed size, there would be no difference between measurement due to differences in screen size. How the empty space next to the maps could be utilised is described in section \ref{MoreInfoPlz}.  
 

\subsection{Search function}
In order to be able to faster navigate the map a search function was created as shown in figure \ref{SearchBar}. 

\begin{figure} [H]
	\centering
	\includegraphics[width=.6\textwidth]{Pictures/SearchBar}
	\caption{The map can pan to a specific area, by searching for that area in the searchbar}
	\label{SearchBar}
\end{figure}

The user can use this to change the current view of the maps to a given location. This is accomplished through the help of Nominatim. This tool can search through Openstreetmap data by location names. It then returns data about the searched location. 

Among this data is the latitude and longitude for the central point of the place. \citep{Nominatim}
This coordinate is then used as the coordinate for the center of the map.

\section{Final product}

This section is an overview of the final product, which can be seen in figure \ref{FinalProduct}. 
The datasets highlighted in the figure is elaborated upon in section \ref{Comparisons}.


\begin{figure} [H]
	\centering
	\includegraphics[width=.8\textwidth]{Pictures/FinalProduct}
	\caption{The final product}
	\label{FinalProduct}
\end{figure}

The main part of the final product is two maps, which are showing two different scenarios for the future. These maps have the same color scale and are always showing the same extent. The values in this color scale are automaticity updated to reflect the highest value within the current extent. The user can see which values the colors are assigned by mousing over the colors. 

Above the two maps are the names of the datasets, which currently are being displayed. Above these names is a search bar, which can be used to pan to a searched location.  

\section{Comparisons}\label{Comparisons}
This section highlights comparisons between different scenarios. 

The datasets, which were displayed in figure \ref{FinalProduct} are SSP1 and SSP3 with GRUMP as urbanisation definition and year 2030. These two scenarios have been chosen, because of their differences as mentioned in section \ref{SSPs}. The first scenario have a low population growth and fast urbanisation rate, whereas the other have a high population growth and slow urbanisation rate. This leads to areas with higher density in the SSP1 scenario, even though there is a bigger population in the SP3 scenario. The faster urbanisation means that this larger population gets spread over a larger area, which lowers the density.

\begin{figure} [H]
	\centering
	\includegraphics[width=.8\textwidth]{Pictures/GlobcoverVsGrump}
	\caption{A comparison between different urbanisation definitions with the same scenario and year}
	\label{GlobcoverVsGrump}
\end{figure}

Figure \ref{GlobcoverVsGrump} shows the difference between the urbanisation definitions. The urban density in much higher, when using the GlobCover definition (right) compared with the GRUMP definition (left). This is due to the fact that both models have the same amount of people living in urban environments, but GRUMP overestimates the urban areas as mentioned in section \ref{TheDataBehind}.  

This mean that a geosimulation with GlobCover as urban definition has smaller areas to squeeze the same population into, which leads to higher densities in the cities.

